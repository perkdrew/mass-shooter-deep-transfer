{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiclass_classifiers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIMzfisa6K0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time, re\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Flatten, LSTM, Bidirectional, Conv1D\n",
        "from keras.layers import Dropout, Activation, MaxPooling1D, SpatialDropout1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers, optimizers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install ktrain\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c40qWI3mJwPf",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pit8C9G1b1v_",
        "colab_type": "text"
      },
      "source": [
        "**Source Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3jnmIcr9CEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9164976b-68ac-42f0-8564-7476b52afbf0"
      },
      "source": [
        "cols = ['sentiment','text']\n",
        "df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/hate25000.csv', encoding='latin-1',\\\n",
        "                 header=None, names=cols, usecols=[5,6])\n",
        "df = df[['text','sentiment']]\n",
        "df.insert(0,'source','hate data')\n",
        "df.head()\n",
        "X = df['text'].fillna('').tolist()\n",
        "X = [str(i) for i in X]\n",
        "X = [re.sub('@[^\\s]+','',i) for i in X]\n",
        "X = [re.sub('RT','',i) for i in X]\n",
        "X = X[1:]\n",
        "\n",
        "y = df['sentiment'].values\n",
        "y = y[1:]\n",
        "\n",
        "print('Source text:',X[0])\n",
        "print('Source label:',y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source text: !!!   As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\n",
            "Source label: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd-oLWaz9oft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0bea5bcf-ac3d-4abc-a7cb-0e86757c9cfd"
      },
      "source": [
        "print('Loading data...')\n",
        "# Balance classes \n",
        "class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Change for each model and iteration!\n",
        "seed = np.random.seed(42)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)\n",
        "\n",
        "# Clean text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convert text to integer sequences\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  \n",
        "print('Found %s unique tokens.' % vocab_size)\n",
        "maxlen = max(len(X) for X in X_train) \n",
        "\n",
        "# Sequences that are shorter than the max length are padded with value\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Found 19333 unique tokens.\n",
            "X_train shape: (16604, 75)\n",
            "X_test shape: (8179, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6uEh1_Rb4mI",
        "colab_type": "text"
      },
      "source": [
        "**Out-of-Sample Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS79VO5pb8tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decontracted(phrase):\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    phrase = re.sub(r\"it\\Õs\", \"it is\", phrase)\n",
        "    phrase = re.sub(r\"don\\Õt\", \"do not\", phrase)\n",
        "    phrase = re.sub(r\"isn\\Õt\", \"is not\", phrase)\n",
        "    phrase = re.sub(r\"I\\Õm\", \"I am\", phrase)\n",
        "    phrase = re.sub(r\"can\\Õt\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"\\Õve\", \"have\", phrase)\n",
        "    return phrase\n",
        "\n",
        "cols_target = [\"target\",\"text\",\"label\"]\n",
        "target_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/multiclass_manifesto.csv', encoding='latin-1', header=None, \\\n",
        "                     names=cols_target, usecols=[0,1,2])\n",
        "target_df = target_df[['target','text',\"label\"]]\n",
        "X_target = target_df['text'].fillna('').tolist()\n",
        "X_target = [decontracted(str(i)) for i in X_target]\n",
        "targ_title = target_df['target'].fillna('').tolist()\n",
        "y_target = target_df[\"label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U6-tuRzz_Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Loading data...\")\n",
        "# Change for each model and iteration!\n",
        "seed = np.random.seed(7)\n",
        "\n",
        "# Balance class weight\n",
        "class_weights_B = compute_class_weight('balanced', np.unique(y_target), y_target)\n",
        "class_weights_B = dict(enumerate(class_weights_B))\n",
        "\n",
        "# Further clean text\n",
        "tokenizer.fit_on_texts(X_target)\n",
        "\n",
        "# Split data\n",
        "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_target, y_target, test_size=0.10, random_state=seed)\n",
        "\n",
        "# Convert text to integer sequences\n",
        "X_train_B = tokenizer.texts_to_sequences(X_train_B)\n",
        "X_test_B = tokenizer.texts_to_sequences(X_test_B)\n",
        "\n",
        "y_train_B = to_categorical(y_train_B, 3)\n",
        "y_test_B = to_categorical(y_test_B, 3)\n",
        "\n",
        "# Sequences that are shorter than the max length are padded with value\n",
        "X_train_B = pad_sequences(X_train_B, padding='post', maxlen=maxlen)\n",
        "X_test_B = pad_sequences(X_test_B, padding='post', maxlen=maxlen)\n",
        "\n",
        "print('X_train shape:', X_train_B.shape)\n",
        "print('X_test shape:', X_test_B.shape)\n",
        "\n",
        "print('y_train shape:', y_train_B.shape)\n",
        "print('y_test shape:', y_test_B.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9UqGwndcFrS",
        "colab_type": "text"
      },
      "source": [
        "# **Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt-0X6p-cLSQ",
        "colab_type": "text"
      },
      "source": [
        "**GloVe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BRvdRWfcKb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_path = '/content/gdrive/My Drive/Colab Notebooks/Data/glove.twitter.27B/glove.twitter.27B.200d.txt'\n",
        "\n",
        "embeddings_index = dict()\n",
        "with open(glove_path,\n",
        "          encoding=\"utf8\") as glove:\n",
        "  for line in glove:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "  glove.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rArKi-eXcREz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 200))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocab_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6bBcf9edKZA",
        "colab_type": "text"
      },
      "source": [
        "# **TextCNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkMKc3ERDH-i",
        "colab_type": "text"
      },
      "source": [
        "**Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqvfMUuJcx9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "#Parameters\n",
        "maxlen = maxlen\n",
        "num_filters = 64\n",
        "weight_decay = 1e-4\n",
        "embedding_dim = 200\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "print('Build CNN model...')\n",
        "model = Sequential()\n",
        "# First layer\n",
        "model.add(Embedding(vocab_size, embedding_dim, \n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=maxlen,\n",
        "                    trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D())\n",
        "# Second layer\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D())\n",
        "# Third layer\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "# CLASSIFICATION\n",
        "# Fully connected layer\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dropout(0.5))\n",
        "# Output layer w/ softmax\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "cnn_history = model.fit(X_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              callbacks=callbacks,\n",
        "              validation_data=(X_test, y_test),\n",
        "              class_weight=class_weights)\n",
        "\n",
        "model.save('my_cnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJIozWopdbsb",
        "colab_type": "text"
      },
      "source": [
        "**Retraining**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEESoRKmhaTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model_A = load_model('my_cnn.h5')\n",
        "\n",
        "cnn_model_B_on_A = Sequential(cnn_model_A.layers[:-1])\n",
        "cnn_model_B_on_A.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "for layer in cnn_model_B_on_A.layers[:-1]:\n",
        "    trainable = True\n",
        "\n",
        "adam = optimizers.Adam(lr=0.007, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "cnn_model_B_on_A.compile(loss=\"categorical_crossentropy\", optimizer=adam,\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "cnn_B_history = cnn_model_B_on_A.fit(X_train_B, y_train_B, epochs=30,\n",
        "                           validation_data=(X_test_B, y_test_B),\n",
        "                           batch_size=16,\n",
        "                           callbacks=callbacks,\n",
        "                           class_weight=class_weights_B)\n",
        "\n",
        "loss, acc = model.evaluate(X_train_B, y_train_B, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(acc))\n",
        "loss, acc = model.evaluate(X_test_B, y_test_B, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(acc))\n",
        "\n",
        "cnn_model_B_on_A.save('my_cnn_B.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41q3ntSRek4o",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzmqQAGNdbAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model = load_model('my_cnn_B.h5')\n",
        "\n",
        "cnn_pred = cnn_model.predict_classes(X_test_B)\n",
        "\n",
        "# Show the inputs and predicted outputs\n",
        "for i in range(850):\n",
        "  print(\"X=%s, Predicted=%s\\n\" % (tokenizer.sequences_to_texts(X_test_B)[i], cnn_pred[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLqinHVnenPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def argmax_keepdims(x, axis):\n",
        "    output_shape = list(x.shape)\n",
        "    output_shape[axis] = 1\n",
        "    return np.argmax(x, axis=axis).reshape(output_shape)\n",
        "\n",
        "y_test_B_fit = argmax_keepdims(y_test_B, axis=1)\n",
        "\n",
        "target_names = ['hate speech', 'offensive language','neither']\n",
        "print('----------------------EVALUATION----------------------\\n')\n",
        "print(classification_report(y_test_B_fit, cnn_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgjfsBeLdxvo",
        "colab_type": "text"
      },
      "source": [
        "# **BiLSTM w/ Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGgCCy234kgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine import Layer, InputSpec\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatibl|e with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "\n",
        "def create_custom_objects():\n",
        "    instance_holder = {\"instance\": None}\n",
        "\n",
        "    class ClassWrapper(AttentionWithContext):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            instance_holder[\"instance\"] = self\n",
        "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def loss(*args):\n",
        "        method = getattr(instance_holder[\"instance\"], \"loss\")\n",
        "        return method(*args)\n",
        "\n",
        "    def acc(*args):\n",
        "        method = getattr(instance_holder[\"instance\"], \"acc\")\n",
        "        return method(*args)\n",
        "    return {\"ClassWrapper\": ClassWrapper ,\"AttentionWithContext\": ClassWrapper, \"loss\": loss,\n",
        "            \"acc\":acc}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhkd_euUIvqj",
        "colab_type": "text"
      },
      "source": [
        "**Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noxZix_hd8Vg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "#Parameters\n",
        "maxlen = maxlen\n",
        "lstm_output_size = 70\n",
        "embedding_dim = 200\n",
        "batch_size = 256\n",
        "kernel_size = 4\n",
        "epochs = 10\n",
        "\n",
        "print('Build LSTM model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, \n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=maxlen,\n",
        "                    trainable=False))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Bidirectional(LSTM(lstm_output_size, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(AttentionWithContext())\n",
        "# Output layer w/ softmax\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "att_history = model.fit(X_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              callbacks=callbacks,\n",
        "              validation_data=(X_test, y_test),\n",
        "              class_weight=class_weights)\n",
        "loss, acc = model.evaluate(X_train, y_train, verbose=1)\n",
        "print(\"Training Accuracy: {:.4f}\".format(acc))\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(acc))\n",
        "\n",
        "model.save('my_att.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stiE5mfXgAIR",
        "colab_type": "text"
      },
      "source": [
        "**Retraining**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuplsRptbe8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_oos, y_oos, test_size=0.33, random_state=33)\n",
        "\n",
        "att_model_B_on_A = Sequential(att_model_A.layers[:-1])\n",
        "att_model_B_on_A.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "for layer in lstm_model_B_on_A.layers[:-1]:\n",
        "    trainable = True\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "att_model_B_on_A.compile(loss=\"categorical_crossentropy\", optimizer=adam,\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "att_B_history = att_model_B_on_A.fit(X_train_B, y_train_B, epochs=10,\n",
        "                           validation_data=(X_test_B, y_test_B),\n",
        "                           callbacks=callbacks)\n",
        "\n",
        "loss, acc = model.evaluate(X_train_B, y_train_B, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(acc))\n",
        "loss, acc = model.evaluate(X_test_B, y_test_B, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(acc))\n",
        "\n",
        "att_model_B_on_A.save('my_att_B.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7TmI0J7f8yF",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEX6BkDWgCXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "att_model = load_model('my_att.h5', custom_objects=create_custom_objects())\n",
        "\n",
        "att_pred = att_model.predict_classes(X_oos)\n",
        "\n",
        "# Show the inputs and predicted outputs\n",
        "for i in range(5):\n",
        "  print(\"X=%s, Predicted=%s\" % (tokenizer.sequences_to_texts(X_oos)[i], att_pred[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDq6WjYZ0tNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def argmax_keepdims(x, axis):\n",
        "    output_shape = list(x.shape)\n",
        "    output_shape[axis] = 1\n",
        "    return np.argmax(x, axis=axis).reshape(output_shape)\n",
        "\n",
        "att_pred_fit = argmax_keepdims(att_pred_prob, axis=1)\n",
        "\n",
        "target_names = ['hate speech', 'offensive language','neither']\n",
        "print('----------------------EVALUATION----------------------\\n')\n",
        "print(classification_report(y_test_B, att_pred_fit, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}