{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multilabel_classifiers.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "v6M870NX_4ZP",
        "P2iMIgPi8ALg"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJUd-1pM68cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "20d8809b-c567-407c-a79b-623884c3eb00"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time, re\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Flatten, LSTM, Bidirectional, Conv1D, GlobalMaxPooling1D\n",
        "from keras.layers import Dropout, Activation, MaxPooling1D, SpatialDropout1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers, optimizers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, multilabel_confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#!pip install ktrain\n",
        "#import ktrain\n",
        "#from ktrain import text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "491kdiFs7syf",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABZKvL_WdJHb",
        "colab_type": "text"
      },
      "source": [
        "**Training/Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqvkMFB38d5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f00b1a9f-01c8-42c8-fc17-d7a94ad5f8b5"
      },
      "source": [
        "toxic_comments = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/toxic160000.csv')\n",
        "\n",
        "filter = toxic_comments[\"comment_text\"] != \"\"\n",
        "toxic_comments = toxic_comments[filter]\n",
        "toxic_comments = toxic_comments.dropna()\n",
        "\n",
        "def preprocess_text(sen):\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "    return sentence\n",
        "\n",
        "X = []\n",
        "sentences = list(toxic_comments[\"comment_text\"])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))\n",
        "\n",
        "toxic_comments_labels = toxic_comments[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "y = toxic_comments_labels.values\n",
        "\n",
        "print('X sample:',X[0])\n",
        "print('y sample:',y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X sample: Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They weren vandalisms just closure on some GAs after voted at New York Dolls FAC And please don remove the template from the talk page since m retired now \n",
            "y sample: [0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jzv-aYh7fGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "85aa48e8-5cd6-4a3f-b9d4-627fa633c2df"
      },
      "source": [
        "print('Loading data...')\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Clean text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "tokenizer.fit_on_texts(X_test)\n",
        "\n",
        "# Convert text to integer sequences\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = 50000\n",
        "maxlen = 150\n",
        "\n",
        "# Sequences that are shorter than the max length are padded with value\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "X_train shape: (106912, 150)\n",
            "X_test shape: (52659, 150)\n",
            "y_train shape: (106912, 6)\n",
            "y_test shape: (52659, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu8lX7r3Muj7",
        "colab_type": "text"
      },
      "source": [
        "**Out-of-Sample Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFQqrj4iMhvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1150fcc7-300d-4734-bfc2-9c1b954095ca"
      },
      "source": [
        "def decontracted(phrase):\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    phrase = re.sub(r\"it\\Õs\", \"it is\", phrase)\n",
        "    phrase = re.sub(r\"don\\Õt\", \"do not\", phrase)\n",
        "    phrase = re.sub(r\"isn\\Õt\", \"is not\", phrase)\n",
        "    phrase = re.sub(r\"I\\Õm\", \"I am\", phrase)\n",
        "    phrase = re.sub(r\"can\\Õt\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"\\Õve\", \"have\", phrase)\n",
        "    return phrase\n",
        "\n",
        "cols_target = [\"target\",\"text\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "target_df = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/Data/multilabel_manifesto.csv\", encoding=\"latin-1\", header=None, \\\n",
        "                     names=cols_target, usecols=[0,1,2,3,4,5,6,7])\n",
        "target_df = target_df[[\"target\",\"text\",\"toxic\",\"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "X_target = target_df[\"text\"].fillna('').tolist()\n",
        "X_target = [decontracted(str(i)) for i in X_target]\n",
        "targ_label = target_df[\"target\"].fillna('').tolist()\n",
        "toxic_target_labels = target_df[[\"toxic\",\"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
        "y_target = toxic_target_labels.values\n",
        "\n",
        "print(\"Target text:\",X_target[0])\n",
        "print(\"Target label:\",y_target[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_oos sample: hate equality, hate tolerance, hate human rights, hate political correctness, hate hypocrisy, hate ignorance, hate enslaving religions and ideologies, hate antidepressants, hate TV soap operas, hate drama shows, hate rap -music, hate mass media, hate censorship, hate political populists, hate religious fanatics, hate moral majority, hate totalitarianism, hate consumerism, hate democracy, hate pacifism, hate state mafia, hate alcoholics, hate TV commercials, hate human race. love existentialism, love self-awareness, love freedom, love justice, love truth, love moral & political philosophy, love personal & social psychology, love evolution science, love political incorrectness, love guns, love shooting, love BDSM, love computers, love internet, love aggressive electronic and industrial rock metal music, love violent movies, love FPS ï¿½computer games, love sarcasm, love irony, love black humour, love macabre artm mass serial killer cases, love natural disasters, love eugenics \n",
            "y_oos sample: [1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJzYpaOGQUus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "98d8879f-5ff5-4a31-b6bb-5890af7bd6fe"
      },
      "source": [
        "print(\"Loading data...\")\n",
        "# Balance classes \n",
        "class_weights = compute_class_weight('balanced', np.unique(y), y)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Change for each model and iteration!\n",
        "seed = np.random.seed(7)\n",
        "\n",
        "# Further clean text\n",
        "tokenizer.fit_on_texts(X_target)\n",
        "\n",
        "# Split data\n",
        "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_target, y_target, test_size=0.33, random_state=seed)\n",
        "\n",
        "# Convert text to integer sequences\n",
        "X_train_B = tokenizer.texts_to_sequences(X_train_B)\n",
        "X_test_B = tokenizer.texts_to_sequences(X_test_B)\n",
        "\n",
        "# Sequences that are shorter than the max length are padded with value\n",
        "X_train_B = pad_sequences(X_train_B, padding='post', maxlen=maxlen)\n",
        "X_test_B = pad_sequences(X_test_B, padding='post', maxlen=maxlen)\n",
        "\n",
        "print('X_train shape:', X_train_B.shape)\n",
        "print('X_test shape:', X_test_B.shape)\n",
        "\n",
        "print('y_train shape:', y_train_B.shape)\n",
        "print('y_test shape:', y_test_B.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "X_train shape: (569, 150)\n",
            "X_test shape: (281, 150)\n",
            "y_train shape: (569, 6)\n",
            "y_test shape: (281, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6M870NX_4ZP",
        "colab_type": "text"
      },
      "source": [
        "# **Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RP1wAJfl-yg",
        "colab_type": "text"
      },
      "source": [
        "**GloVe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCYwutnz_9dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_path = \"/content/gdrive/My Drive/Colab Notebooks/Data/glove.twitter.27B/glove.twitter.27B.50d.txt\"\n",
        "\n",
        "embeddings_index = dict()\n",
        "with open(glove_path,\n",
        "          encoding=\"utf8\") as glove:\n",
        "  for line in glove:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype=\"float32\")\n",
        "    embeddings_index[word] = coefs\n",
        "  glove.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BvYY4Yq_-4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 50))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocab_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv_r0Vg7X3Qt",
        "colab_type": "text"
      },
      "source": [
        "# **Algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xMI14NGX9rN",
        "colab_type": "text"
      },
      "source": [
        "**Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NzAt7ZMX8Bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine import Layer, InputSpec\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "    \n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.softmax(ait)\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "\n",
        "def create_custom_objects():\n",
        "    instance_holder = {\"instance\": None}\n",
        "\n",
        "    class ClassWrapper(AttentionWithContext):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            instance_holder[\"instance\"] = self\n",
        "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def loss(*args):\n",
        "        method = getattr(instance_holder[\"instance\"], \"loss_function\")\n",
        "        return method(*args)\n",
        "\n",
        "    def acc(*args):\n",
        "        method = getattr(instance_holder[\"instance\"], \"accuracy\")\n",
        "        return method(*args)\n",
        "    return {\"ClassWrapper\": ClassWrapper ,\"AttentionWithContext\": ClassWrapper, \"loss\": loss,\n",
        "            \"acc\":acc}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2iMIgPi8ALg",
        "colab_type": "text"
      },
      "source": [
        "# **Baseline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZnKRfj-0uYk",
        "colab_type": "text"
      },
      "source": [
        "**MultinomialNB for Multilabel (6-Label) Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMiSztD5o8Ru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "a34d29c6-7266-4f89-8ac5-f83fa3937a77"
      },
      "source": [
        "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_oos, y_oos, test_size=0.33, random_state=42, shuffle=True)\n",
        "\n",
        "# Combine a text feature extractor with multilabel classifier\n",
        "NB_pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
        "    ('classifier', OneVsRestClassifier(MultinomialNB(fit_prior=True, class_prior=None))),\n",
        "])\n",
        "\n",
        "NB_pipeline.fit(X_train_B, y_train_B)\n",
        "NB_pred = NB_pipeline.predict(X_test_B)\n",
        "cm = multilabel_confusion_matrix(y_test_B, NB_pred) \n",
        "print(\"Accuracy: %s\" % NB_pipeline.score(X_test_B, y_test_B))\n",
        "print(\"Confusion Matrix:\\n %s\" % cm)\n",
        "print(\"AUC %s\" % roc_auc_score(y_test_B, NB_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6334519572953736\n",
            "Confusion Matrix:\n",
            " [[[215   0]\n",
            "  [ 65   1]]\n",
            "\n",
            " [[249   0]\n",
            "  [ 32   0]]\n",
            "\n",
            " [[249   0]\n",
            "  [ 32   0]]\n",
            "\n",
            " [[232   0]\n",
            "  [ 49   0]]\n",
            "\n",
            " [[238   0]\n",
            "  [ 43   0]]\n",
            "\n",
            " [[248   0]\n",
            "  [ 33   0]]]\n",
            "AUC 0.5012626262626263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDHmqpXh8Ag7",
        "colab_type": "text"
      },
      "source": [
        "# **TextCNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km40EnU1R2Bm",
        "colab_type": "text"
      },
      "source": [
        "**Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYzANcOu8IhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "85730b52-09fe-46a9-baca-77f3bfe9b36a"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Parameters\n",
        "maxlen = maxlen\n",
        "num_filters = 32\n",
        "weight_decay = 1e-4\n",
        "embedding_dim = 50\n",
        "batch_size = 128\n",
        "pool_size = 2\n",
        "epochs = 20\n",
        "\n",
        "print('Build CNN model...')\n",
        "model = Sequential()\n",
        "# First layer\n",
        "model.add(Embedding(vocab_size, embedding_dim, \n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=maxlen,\n",
        "                    trainable=False))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='valid'))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "# Second layer\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "# Third layer\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "model.add(Flatten())\n",
        "# CLASSIFICATION\n",
        "# Fully connected layer\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Dropout(0.2))\n",
        "# Output layer w/ sigmoid\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "cnn_history = model.fit(X_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              callbacks=callbacks)\n",
        "\n",
        "model.save('my_cnn.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build CNN model...\n",
            "Epoch 1/20\n",
            "106912/106912 [==============================] - 27s 249us/step - loss: 0.1360 - acc: 0.9636\n",
            "Epoch 2/20\n",
            "  2560/106912 [..............................] - ETA: 6s - loss: 0.1037 - acc: 0.9691"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.1035 - acc: 0.9688\n",
            "Epoch 3/20\n",
            "106912/106912 [==============================] - 7s 65us/step - loss: 0.0949 - acc: 0.9710\n",
            "Epoch 4/20\n",
            "106912/106912 [==============================] - 7s 65us/step - loss: 0.0907 - acc: 0.9722\n",
            "Epoch 5/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0869 - acc: 0.9729\n",
            "Epoch 6/20\n",
            "106912/106912 [==============================] - 7s 64us/step - loss: 0.0845 - acc: 0.9734\n",
            "Epoch 7/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0830 - acc: 0.9741\n",
            "Epoch 8/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0817 - acc: 0.9743\n",
            "Epoch 9/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0800 - acc: 0.9747\n",
            "Epoch 10/20\n",
            "106912/106912 [==============================] - 7s 62us/step - loss: 0.0787 - acc: 0.9752\n",
            "Epoch 11/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0776 - acc: 0.9753\n",
            "Epoch 12/20\n",
            "106912/106912 [==============================] - 7s 64us/step - loss: 0.0764 - acc: 0.9757\n",
            "Epoch 13/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0759 - acc: 0.9758\n",
            "Epoch 14/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0759 - acc: 0.9758\n",
            "Epoch 15/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0743 - acc: 0.9762\n",
            "Epoch 16/20\n",
            "106912/106912 [==============================] - 7s 64us/step - loss: 0.0746 - acc: 0.9759\n",
            "Epoch 17/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0738 - acc: 0.9761\n",
            "Epoch 18/20\n",
            "106912/106912 [==============================] - 7s 65us/step - loss: 0.0733 - acc: 0.9765\n",
            "Epoch 19/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0722 - acc: 0.9767\n",
            "Epoch 20/20\n",
            "106912/106912 [==============================] - 7s 63us/step - loss: 0.0725 - acc: 0.9766\n",
            "CPU times: user 3min 46s, sys: 8.21 s, total: 3min 55s\n",
            "Wall time: 3min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3JXNvAqL3fH",
        "colab_type": "text"
      },
      "source": [
        "**Retraining**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW3s13eML2tA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "15428672-c84c-41df-c336-2d682a509307"
      },
      "source": [
        "cnn_model_A = load_model('my_cnn.h5')\n",
        "\n",
        "cnn_model_B_on_A = Sequential(cnn_model_A.layers[:-1])\n",
        "cnn_model_B_on_A.add(Dense(6, activation=\"sigmoid\"))\n",
        "\n",
        "for layer in cnn_model_B_on_A.layers[:-1]:\n",
        "    trainable = True\n",
        "\n",
        "adam = optimizers.Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "cnn_model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=adam,\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "cnn_B_history = cnn_model_B_on_A.fit(X_train_B, y_train_B, epochs=20,\n",
        "                           validation_data=(X_test_B, y_test_B),\n",
        "                           batch_size=32,\n",
        "                           callbacks=callbacks)\n",
        "\n",
        "loss, acc = model.evaluate(X_train_B, y_train_B, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(acc))\n",
        "loss, acc = model.evaluate(X_test_B, y_test_B, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(acc))\n",
        "\n",
        "cnn_model_B_on_A.save('my_cnn_B.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 569 samples, validate on 281 samples\n",
            "Epoch 1/20\n",
            "569/569 [==============================] - 23s 41ms/step - loss: 0.5038 - acc: 0.8149 - val_loss: 0.4364 - val_acc: 0.8286\n",
            "Epoch 2/20\n",
            "569/569 [==============================] - 0s 307us/step - loss: 0.4192 - acc: 0.8333 - val_loss: 0.4017 - val_acc: 0.8292\n",
            "Epoch 3/20\n",
            "569/569 [==============================] - 0s 289us/step - loss: 0.3835 - acc: 0.8374 - val_loss: 0.3788 - val_acc: 0.8321\n",
            "Epoch 4/20\n",
            "569/569 [==============================] - 0s 332us/step - loss: 0.3618 - acc: 0.8433 - val_loss: 0.3672 - val_acc: 0.8357\n",
            "Epoch 5/20\n",
            "569/569 [==============================] - 0s 298us/step - loss: 0.3413 - acc: 0.8559 - val_loss: 0.3685 - val_acc: 0.8399\n",
            "Epoch 6/20\n",
            "569/569 [==============================] - 0s 307us/step - loss: 0.3220 - acc: 0.8597 - val_loss: 0.3647 - val_acc: 0.8416\n",
            "Epoch 7/20\n",
            "569/569 [==============================] - 0s 290us/step - loss: 0.3018 - acc: 0.8626 - val_loss: 0.3796 - val_acc: 0.8393\n",
            "569/569 [==============================] - 9s 15ms/step\n",
            "Training Accuracy: 0.8363\n",
            "Testing Accuracy:  0.8327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7LBE2ik9mKq",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvMV6-J7TNWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "180b6fd1-9597-447c-ec07-422447e7b12e"
      },
      "source": [
        "cnn_model_B = load_model('my_cnn_B.h5')\n",
        "\n",
        "# Probability predictions of labels\n",
        "y_pred = cnn_model_B.predict(X_test_B)\n",
        "\n",
        "# Show the inputs and predicted outputs\n",
        "for i in range(5):\n",
        "  print(\"X=%s\\n Predicted=%s\\n\" % (tokenizer.sequences_to_texts(X_test_B)[i], y_pred[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X=they for make an except to avoid situation guys for not tagged this to the awards has that detail this that just negative no the elvis to the nonetheless if not or it adminship change if or image without of them for own just is source the obviously and the his discussion for not legal after it wrong www dropped to on of composer adults just is tendency of they for because into like from site for will not for haven have of for are to rvv an it an wanting all make penis government to insert make section source the his\n",
            " Predicted=[0.24200931 0.10111693 0.05809367 0.1396718  0.1226202  0.15338951]\n",
            "\n",
            "X=be minds with wales of many this the favor and the his of the small com to to the verifiable nhrhs pursue improved and the live in it people state his style fi primary your design on of in blocked primary the effort few and century be celebrity the quickly and the his to system of to kingdom notion in me topic whatever on what is his style of be celebrity so to editors dealing believe have the and or disruptive and http so been\n",
            " Predicted=[0.08299121 0.00097659 0.00083268 0.02003336 0.0116004  0.01545835]\n",
            "\n",
            "X=house edit add dude to andrew editing has plural for verse for has an above against for will to talk will to time of will to doesn has for anyhow for asking for just content for but edit add dude to their flying editing sound editing was sound story of sound portal for not as reinstated for not as for not editing for are the may and fair it an portal for edit say please the say the of the flying house edit put have bottom put have contested\n",
            " Predicted=[0.4074853  0.11158684 0.09663498 0.34160367 0.1871211  0.22298583]\n",
            "\n",
            "X=agree bark that is song look you how you your never power one your for of same utc post be your on constitutes of is your who pages to such accusations from could this that rape to during removed if could on is simple right discussion that is result aka have for following wow same that is same has revolution if generally seeks of only let page contest let if while in no ve if nor my former page it option page it would all know thank not like of know thank talk for time not of as unofficial\n",
            " Predicted=[0.33530658 0.10695341 0.03337744 0.15296322 0.10579181 0.1375967 ]\n",
            "\n",
            "X=allow you why might is prior you why as discussion east to perfect article ones you why as discussion to links of these an ones you why as discussion to asian page perfect back in be complaints don also this that other have who to do looked of system in this that speedy have who to too being in be are the take vandalism is service vandalism is vandalism in your them for brazilian instead hello for not is griffin page is page is prior page is usual hello for not shot page hello for go my the page it the for not ll to brazilian instead some just you why be not or it the take advised of be or not ll to brazilian the take instead no the take thanks more some ban to on is even thanks or and who are accordingly discussion it with questions without realise there the summary and the even thanks interesting adopted there the summary and the even thanks of off reversion there the summary and the even thanks\n",
            " Predicted=[0.06276616 0.04904348 0.09157175 0.07143018 0.06560269 0.02765739]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j55ByiojqmGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_pred(pred_tensor):\n",
        "  with np.nditer(pred_tensor, op_flags=['readwrite']) as it:\n",
        "    for x in it:\n",
        "      if x >= 0.1:\n",
        "        x[...] = 1\n",
        "      else:\n",
        "        x[...] = 0\n",
        "  return pred_tensor\n",
        "\n",
        "cnn_predict_fit = convert_pred(y_pred).astype('int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn8FsStPn0mp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "224db9e1-0380-4000-ee6e-4c2bca1bc521"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "print(\"ROC score: %s\" % roc_auc_score(y_test_B, cnn_predict_fit))\n",
        "print(\"AP score: %s\\n\" % average_precision_score(y_test_B, cnn_predict_fit))\n",
        "print(\"Confusion Matrix:\\n %s\" % multilabel_confusion_matrix(y_test_B, cnn_predict_fit))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC score: 0.7222756689525167\n",
            "AP score: 0.29793119942582685\n",
            "\n",
            "Confusion Matrix:\n",
            " [[[ 82 118]\n",
            "  [  1  80]]\n",
            "\n",
            " [[223  26]\n",
            "  [ 13  19]]\n",
            "\n",
            " [[179  74]\n",
            "  [  6  22]]\n",
            "\n",
            " [[143  86]\n",
            "  [ 13  39]]\n",
            "\n",
            " [[165  68]\n",
            "  [ 11  37]]\n",
            "\n",
            " [[169  64]\n",
            "  [ 14  34]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU1Au0TW751N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "2acbd8bf-467e-46d1-bd02-563fac164d25"
      },
      "source": [
        "multilabels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "print('----------------------EVALUATION----------------------\\n')\n",
        "print(classification_report(y_test_B, cnn_predict_fit, labels=(0,1,2,3,4,5), target_names=multilabels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------EVALUATION----------------------\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.41      0.89      0.56        81\n",
            " severe_toxic       0.26      0.56      0.36        32\n",
            "      obscene       0.23      0.75      0.36        28\n",
            "       threat       0.35      0.79      0.48        52\n",
            "       insult       0.34      0.71      0.46        48\n",
            "identity_hate       0.25      0.52      0.33        48\n",
            "\n",
            "    micro avg       0.32      0.73      0.45       289\n",
            "    macro avg       0.31      0.70      0.43       289\n",
            " weighted avg       0.33      0.73      0.45       289\n",
            "  samples avg       0.20      0.31      0.22       289\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3TY4Fd707-e",
        "colab_type": "text"
      },
      "source": [
        "# **BiLSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz1fBCda2Epj",
        "colab_type": "text"
      },
      "source": [
        "**Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfEPTGkR1ACZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "754471ce-0851-41c7-c472-a4ca5649913a"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Parameters\n",
        "maxlen = maxlen\n",
        "lstm_output_size = 64\n",
        "embedding_dim = 50\n",
        "batch_size = 256\n",
        "epochs = 5\n",
        "\n",
        "print('Build LSTM model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, \n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=maxlen,\n",
        "                    trainable=False))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Bidirectional(LSTM(lstm_output_size, dropout=0.2, recurrent_dropout=0.2)))\n",
        "# Output layer w/ sigmoid\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "lstm_history = model.fit(X_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              callbacks=callbacks,\n",
        "              validation_data=(X_test, y_test))\n",
        "\n",
        "model.save('my_lstm.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build LSTM model...\n",
            "Train on 106912 samples, validate on 52659 samples\n",
            "Epoch 1/5\n",
            "106912/106912 [==============================] - 278s 3ms/step - loss: 0.1552 - acc: 0.9577 - val_loss: 0.1255 - val_acc: 0.9630\n",
            "Epoch 2/5\n",
            "106912/106912 [==============================] - 252s 2ms/step - loss: 0.1159 - acc: 0.9650 - val_loss: 0.1045 - val_acc: 0.9672\n",
            "Epoch 3/5\n",
            "106912/106912 [==============================] - 252s 2ms/step - loss: 0.1063 - acc: 0.9671 - val_loss: 0.0984 - val_acc: 0.9690\n",
            "Epoch 4/5\n",
            "106912/106912 [==============================] - 252s 2ms/step - loss: 0.1001 - acc: 0.9689 - val_loss: 0.0922 - val_acc: 0.9707\n",
            "Epoch 5/5\n",
            "106912/106912 [==============================] - 249s 2ms/step - loss: 0.0959 - acc: 0.9702 - val_loss: 0.0871 - val_acc: 0.9726\n",
            "CPU times: user 33min 35s, sys: 4min 35s, total: 38min 11s\n",
            "Wall time: 22min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSwSh725VCOD",
        "colab_type": "text"
      },
      "source": [
        "**Retraining**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KReDeRgHUcQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "2601b365-c92c-418c-f473-fae86ebd5584"
      },
      "source": [
        "lstm_model_A = load_model(\"my_lstm.h5\")\n",
        "\n",
        "lstm_model_B_on_A = Sequential(lstm_model_A.layers[:-1])\n",
        "lstm_model_B_on_A.add(Dense(6, activation=\"sigmoid\"))\n",
        "\n",
        "for layer in lstm_model_B_on_A.layers[:-1]:\n",
        "    trainable = True\n",
        "\n",
        "adam = optimizers.Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "lstm_model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=adam,\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "lstm_B_history = lstm_model_B_on_A.fit(X_train_B, y_train_B, epochs=20,\n",
        "                           validation_data=(X_test_B, y_test_B),\n",
        "                           batch_size=32,\n",
        "                           callbacks=callbacks)\n",
        "\n",
        "loss, acc = model.evaluate(X_train_B, y_train_B, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(acc))\n",
        "loss, acc = model.evaluate(X_test_B, y_test_B, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(acc))\n",
        "\n",
        "lstm_model_B_on_A.save(\"my_lstm_B.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 569 samples, validate on 281 samples\n",
            "Epoch 1/20\n",
            "569/569 [==============================] - 37s 65ms/step - loss: 0.7270 - acc: 0.5360 - val_loss: 0.5310 - val_acc: 0.8286\n",
            "Epoch 2/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.4772 - acc: 0.8319 - val_loss: 0.4419 - val_acc: 0.8286\n",
            "Epoch 3/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.4346 - acc: 0.8336 - val_loss: 0.4330 - val_acc: 0.8286\n",
            "Epoch 4/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.4255 - acc: 0.8336 - val_loss: 0.4286 - val_acc: 0.8286\n",
            "Epoch 5/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.4199 - acc: 0.8336 - val_loss: 0.4192 - val_acc: 0.8286\n",
            "Epoch 6/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.4128 - acc: 0.8342 - val_loss: 0.4175 - val_acc: 0.8286\n",
            "Epoch 7/20\n",
            "569/569 [==============================] - 11s 20ms/step - loss: 0.4112 - acc: 0.8348 - val_loss: 0.4098 - val_acc: 0.8304\n",
            "Epoch 8/20\n",
            "569/569 [==============================] - 11s 20ms/step - loss: 0.4031 - acc: 0.8345 - val_loss: 0.4085 - val_acc: 0.8327\n",
            "Epoch 9/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.4000 - acc: 0.8383 - val_loss: 0.4042 - val_acc: 0.8327\n",
            "Epoch 10/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3864 - acc: 0.8421 - val_loss: 0.3945 - val_acc: 0.8369\n",
            "Epoch 11/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3834 - acc: 0.8459 - val_loss: 0.3917 - val_acc: 0.8387\n",
            "Epoch 12/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3823 - acc: 0.8480 - val_loss: 0.3851 - val_acc: 0.8375\n",
            "Epoch 13/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3758 - acc: 0.8503 - val_loss: 0.3938 - val_acc: 0.8422\n",
            "Epoch 14/20\n",
            "569/569 [==============================] - 11s 20ms/step - loss: 0.3771 - acc: 0.8456 - val_loss: 0.3770 - val_acc: 0.8422\n",
            "Epoch 15/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3700 - acc: 0.8521 - val_loss: 0.3777 - val_acc: 0.8434\n",
            "Epoch 16/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3694 - acc: 0.8477 - val_loss: 0.3649 - val_acc: 0.8452\n",
            "Epoch 17/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3771 - acc: 0.8468 - val_loss: 0.3703 - val_acc: 0.8452\n",
            "Epoch 18/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3660 - acc: 0.8509 - val_loss: 0.3647 - val_acc: 0.8428\n",
            "Epoch 19/20\n",
            "569/569 [==============================] - 11s 19ms/step - loss: 0.3590 - acc: 0.8477 - val_loss: 0.3678 - val_acc: 0.8345\n",
            "569/569 [==============================] - 4s 6ms/step\n",
            "Training Accuracy: 0.8339\n",
            "Testing Accuracy:  0.8262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCW02u5G1-1x",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XuQSo-91zVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e7012713-4447-45d4-f8c6-9e30de084104"
      },
      "source": [
        "lstm_model_B = load_model('my_lstm_B.h5')\n",
        "\n",
        "# Probability predictions of labels\n",
        "y_pred = lstm_model_B.predict(X_test_B)\n",
        "\n",
        "# Show the inputs and predicted outputs\n",
        "for i in range(5):\n",
        "  print(\"X=%s\\n Predicted=%s\\n\" % (tokenizer.sequences_to_texts(X_test_B)[i], y_pred[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X=when you take your case to washington d c you are taking it to the criminal who is responsible it is like running from the wolf to the fox they are all in cahoots together they all work political chicanery and make you look like a chump before the eyes of the world here you are walking around in america getting ready to be drafted and sent abroad like a tin soldier and when you get over there people ask you what are you fighting for and you have to stick your tongue in your cheek no take uncle sam to court take him before the world\n",
            " Predicted=[0.44167832 0.18228698 0.14604259 0.2972779  0.33124894 0.26217866]\n",
            "\n",
            "X=we invite this congress and through it the scientists of the world and the general public to subscribe to the following resolution ï¿½in view of the fact that in any future world war nuclear weapons will certainly be employed and that such weapons threaten the continued existence of mankind we urge the governments of the world to realize and to acknowledge publicly that their purpose cannot be furthered by a world war and we urge them consequently to find peaceful means for the settlement of all matters of dispute between them ï¿½\n",
            " Predicted=[0.22920859 0.04100415 0.02199724 0.12765417 0.08503932 0.15340951]\n",
            "\n",
            "X=soldiers donï¿½t give yourselves to brutes men who despise you enslave you who regiment your lives tell you what to do what to think and what to feel who drill you diet you treat you like cattle use you as cannon fodder donï¿½t give yourselves to these unnatural men machine men with machine minds and machine hearts you are not machines you are not cattle you are men you have the love of humanity in your hearts you donï¿½t hate only the unloved hate the unloved and the unnatural soldiers donï¿½t fight for slavery fight for liberty\n",
            " Predicted=[0.35103002 0.38110244 0.4856467  0.48124695 0.57746255 0.2261912 ]\n",
            "\n",
            "X=self awareness is a wonderful thing i know i will die soon so will you and everyone else maybe we will be lucky and a comet will smash us back to day 1 people say it is immoral to follow others they say be a leader well here is a fuckin news flash for you stupid shits everyone is a follower everyone who says they arenï¿½t followers and then dresses different or acts different they got that from something they saw on tv or in film or in life no originality how many yo mamma jokes are there and how many do you think are original and not copied keine\n",
            " Predicted=[0.4333154  0.4465217  0.533349   0.5271794  0.6646978  0.27424473]\n",
            "\n",
            "X=discuss anything that we differ about because it is time for us to submerge our differences and realize that it is best for us to first see that we have the same problem a common problem a problem that will make you catch hell whether you are a baptist or a methodist or a muslim or a nationalist whether you are educated or illiterate whether you live on the boulevard or in the alley you are going to catch hell just like i am we are all in the same boat and we all are going to catch the same hell from the same man he just happens to be a white man all of us have suffered here in this country political oppression at the hands of the white man economic exploitation at the hands of the white man and social degradation at the hands of the white man\n",
            " Predicted=[0.20561731 0.65728676 0.7932817  0.5560352  0.749995   0.19184706]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbwV1Oe08Odt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_pred(pred_tensor):\n",
        "  with np.nditer(pred_tensor, op_flags=['readwrite']) as it:\n",
        "    for x in it:\n",
        "      if x >= 0.4:\n",
        "        x[...] = 1\n",
        "      else:\n",
        "        x[...] = 0\n",
        "  return pred_tensor\n",
        "\n",
        "lstm_predict_fit = convert_pred(y_pred).astype('int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSZfai4DPuWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "5e0e459d-68c4-4c4c-94df-d963f23022de"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "print(\"ROC score: %s\" % roc_auc_score(y_test_B, y_pred))\n",
        "print(\"AP score: %s\\n\" % average_precision_score(y_test_B, y_pred))\n",
        "\n",
        "multilabels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "print('----------------------EVALUATION----------------------\\n')\n",
        "print(classification_report(y_test_B, lstm_predict_fit, labels=(0,1,2,3,4,5), target_names=multilabels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC score: 0.6509899713772902\n",
            "AP score: 0.3009683484291788\n",
            "\n",
            "Confusion Matrix:\n",
            " [[[181  19]\n",
            "  [ 60  21]]\n",
            "\n",
            " [[232  17]\n",
            "  [ 17  15]]\n",
            "\n",
            " [[236  17]\n",
            "  [  7  21]]\n",
            "\n",
            " [[208  21]\n",
            "  [ 37  15]]\n",
            "\n",
            " [[207  26]\n",
            "  [ 25  23]]\n",
            "\n",
            " [[233   0]\n",
            "  [ 48   0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X6XcECWGVq2",
        "colab_type": "text"
      },
      "source": [
        "# **BiLSTM w/ Attention**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7PSJgmuYEXw",
        "colab_type": "text"
      },
      "source": [
        "**Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ets98VKIGQlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "0d380d10-3505-4ad2-ec75-2dd2a7e140f3"
      },
      "source": [
        "%%time\n",
        "\n",
        "#Parameters\n",
        "maxlen = maxlen\n",
        "num_filters = 64\n",
        "lstm_output_size = 128\n",
        "weight_decay = 1e-4\n",
        "embedding_dim = 50\n",
        "batch_size = 128\n",
        "kernel_size = 4\n",
        "pool_size = 4\n",
        "epochs = 5\n",
        "\n",
        "print('Build ATT model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, \n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=maxlen,\n",
        "                    trainable=False))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Conv1D(num_filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "model.add(Bidirectional(LSTM(lstm_output_size, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(AttentionWithContext())\n",
        "# Output layer w/ sigmoid\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "att_history = model.fit(X_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              callbacks=callbacks,\n",
        "              validation_data=(X_test, y_test))\n",
        "\n",
        "model.save('my_att.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build ATT model...\n",
            "Train on 106912 samples, validate on 52659 samples\n",
            "Epoch 1/5\n",
            "106912/106912 [==============================] - 166s 2ms/step - loss: 0.1215 - acc: 0.9651 - val_loss: 0.0972 - val_acc: 0.9702\n",
            "Epoch 2/5\n",
            "106912/106912 [==============================] - 137s 1ms/step - loss: 0.0946 - acc: 0.9709 - val_loss: 0.0888 - val_acc: 0.9725\n",
            "Epoch 3/5\n",
            "106912/106912 [==============================] - 136s 1ms/step - loss: 0.0870 - acc: 0.9731 - val_loss: 0.0836 - val_acc: 0.9741\n",
            "Epoch 4/5\n",
            "106912/106912 [==============================] - 137s 1ms/step - loss: 0.0831 - acc: 0.9739 - val_loss: 0.0823 - val_acc: 0.9745\n",
            "Epoch 5/5\n",
            "106912/106912 [==============================] - 136s 1ms/step - loss: 0.0805 - acc: 0.9745 - val_loss: 0.0780 - val_acc: 0.9753\n",
            "CPU times: user 17min 59s, sys: 2min 5s, total: 20min 4s\n",
            "Wall time: 12min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAXMB2yfj6tt",
        "colab_type": "text"
      },
      "source": [
        "**Retraining**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHRD0JSQXfFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "att_model_A = load_model('my_att.h5', custom_objects=create_custom_objects())\n",
        "\n",
        "att_model_B_on_A = Sequential(att_model_A.layers[:-1])\n",
        "att_model_B_on_A.add(Dense(6, activation=\"sigmoid\"))\n",
        "\n",
        "for layer in lstm_model_B_on_A.layers[:-1]:\n",
        "    trainable = True\n",
        "\n",
        "adam = optimizers.Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "att_model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=adam,\n",
        "                     metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0)\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "att_B_history = att_model_B_on_A.fit(X_train_B, y_train_B, epochs=20,\n",
        "                           validation_data=(X_test_B, y_test_B),\n",
        "                           callbacks=callbacks)\n",
        "\n",
        "loss, acc = model.evaluate(X_train_B, y_train_B, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(acc))\n",
        "loss, acc = model.evaluate(X_test_B, y_test_B, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(acc))\n",
        "\n",
        "att_model_B_on_A.save('my_att_B.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72EF_DyRj93X",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf3pU6pAMG_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a946ace6-bbec-49ba-8bbc-d6ad789d0c6e"
      },
      "source": [
        "att_model_B = load_model('my_att_B.h5', custom_objects=create_custom_objects())\n",
        "\n",
        "# Probability predictions of labels\n",
        "y_pred = att_model_B.predict(X_test_B)\n",
        "\n",
        "# Show the inputs and predicted outputs\n",
        "for i in range(5):\n",
        "  print(\"X=%s\\n Predicted=%s\\n\" % (tokenizer.sequences_to_texts(X_test_B)[i], y_pred[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X=when you take your case to washington d c you are taking it to the criminal who is responsible it is like running from the wolf to the fox they are all in cahoots together they all work political chicanery and make you look like a chump before the eyes of the world here you are walking around in america getting ready to be drafted and sent abroad like a tin soldier and when you get over there people ask you what are you fighting for and you have to stick your tongue in your cheek no take uncle sam to court take him before the world\n",
            " Predicted=[0.26227805 0.06249803 0.03448489 0.14164007 0.09361386 0.13231012]\n",
            "\n",
            "X=we invite this congress and through it the scientists of the world and the general public to subscribe to the following resolution ï¿½in view of the fact that in any future world war nuclear weapons will certainly be employed and that such weapons threaten the continued existence of mankind we urge the governments of the world to realize and to acknowledge publicly that their purpose cannot be furthered by a world war and we urge them consequently to find peaceful means for the settlement of all matters of dispute between them ï¿½\n",
            " Predicted=[0.31425306 0.01788387 0.00609255 0.07758933 0.07253981 0.13767672]\n",
            "\n",
            "X=soldiers donï¿½t give yourselves to brutes men who despise you enslave you who regiment your lives tell you what to do what to think and what to feel who drill you diet you treat you like cattle use you as cannon fodder donï¿½t give yourselves to these unnatural men machine men with machine minds and machine hearts you are not machines you are not cattle you are men you have the love of humanity in your hearts you donï¿½t hate only the unloved hate the unloved and the unnatural soldiers donï¿½t fight for slavery fight for liberty\n",
            " Predicted=[0.40445825 0.3197213  0.3754295  0.45005968 0.53599393 0.20991349]\n",
            "\n",
            "X=self awareness is a wonderful thing i know i will die soon so will you and everyone else maybe we will be lucky and a comet will smash us back to day 1 people say it is immoral to follow others they say be a leader well here is a fuckin news flash for you stupid shits everyone is a follower everyone who says they arenï¿½t followers and then dresses different or acts different they got that from something they saw on tv or in film or in life no originality how many yo mamma jokes are there and how many do you think are original and not copied keine\n",
            " Predicted=[0.30072016 0.21885154 0.22900093 0.30612543 0.2711541  0.11279523]\n",
            "\n",
            "X=discuss anything that we differ about because it is time for us to submerge our differences and realize that it is best for us to first see that we have the same problem a common problem a problem that will make you catch hell whether you are a baptist or a methodist or a muslim or a nationalist whether you are educated or illiterate whether you live on the boulevard or in the alley you are going to catch hell just like i am we are all in the same boat and we all are going to catch the same hell from the same man he just happens to be a white man all of us have suffered here in this country political oppression at the hands of the white man economic exploitation at the hands of the white man and social degradation at the hands of the white man\n",
            " Predicted=[0.38201365 0.4319632  0.58225334 0.4753398  0.5414378  0.140336  ]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHCyJEH6GZzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_pred(pred_tensor):\n",
        "  with np.nditer(pred_tensor, op_flags=['readwrite']) as it:\n",
        "    for x in it:\n",
        "      if x >= 0.1:\n",
        "        x[...] = 1\n",
        "      else:\n",
        "        x[...] = 0\n",
        "  return pred_tensor\n",
        "\n",
        "att_predict_fit = convert_pred(y_pred).astype('int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cnyz6ojj9BE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "6a4dec47-ac2d-473a-fe79-f6a654d7dc45"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "print(\"ROC score: %s\" % roc_auc_score(y_test_B, att_predict_fit))\n",
        "print(\"AP score: %s\\n\" % average_precision_score(y_test_B, att_predict_fit))\n",
        "print(\"Confusion Matrix:\\n %s\" % multilabel_confusion_matrix(y_test_B, att_predict_fit))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC score: 0.5393584091257911\n",
            "AP score: 0.16550538048559946\n",
            "\n",
            "Confusion Matrix:\n",
            " [[[ 65 140]\n",
            "  [ 16  60]]\n",
            "\n",
            " [[200  59]\n",
            "  [ 19   3]]\n",
            "\n",
            " [[204  46]\n",
            "  [ 24   7]]\n",
            "\n",
            " [[120 113]\n",
            "  [ 17  31]]\n",
            "\n",
            " [[139 100]\n",
            "  [ 20  22]]\n",
            "\n",
            " [[114 132]\n",
            "  [ 11  24]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZGNDmQsGk55",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "2c0ca104-182d-4c91-ddcb-b68e66626ea2"
      },
      "source": [
        "multilabels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "print('----------------------EVALUATION----------------------\\n')\n",
        "print(classification_report(y_test_B, att_predict_fit, labels=(0,1,2,3,4,5), target_names=multilabels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------EVALUATION----------------------\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.40      0.99      0.57        81\n",
            " severe_toxic       0.42      0.59      0.49        32\n",
            "      obscene       0.23      0.79      0.35        28\n",
            "       threat       0.31      0.75      0.44        52\n",
            "       insult       0.35      0.77      0.48        48\n",
            "identity_hate       0.35      0.71      0.47        48\n",
            "\n",
            "    micro avg       0.35      0.80      0.48       289\n",
            "    macro avg       0.34      0.77      0.47       289\n",
            " weighted avg       0.35      0.80      0.49       289\n",
            "  samples avg       0.22      0.34      0.25       289\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-g9Fscb-bZB",
        "colab_type": "text"
      },
      "source": [
        "# **BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GL8s1Zz-8tA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "70744bcc-2943-40bf-a6e0-2f48b12ad101"
      },
      "source": [
        "toxic_path = '/content/gdrive/My Drive/Colab Notebooks/Data/bert_multilabel.csv'\n",
        "label_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \n",
        "                 \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "(X_train_bert, y_train_bert), (X_test_bert, y_test_bert), preproc = text.texts_from_csv(toxic_path, \"text\",\n",
        "                                                                    label_columns=label_columns, \n",
        "                                                                    max_features=vocab_size, \n",
        "                                                                    maxlen=maxlen,\n",
        "                                                                    preprocess_mode=\"bert\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "detected encoding: utf-8 (if wrong, set manually)\n",
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv7RbWPZANiL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b890b997-c7f1-4158-ceac-2800fb574324"
      },
      "source": [
        "model = text.text_classifier(\"bert\", (X_train_bert, y_train_bert), preproc=preproc, multilabel=True)\n",
        "learner = ktrain.get_learner(model, train_data=(X_train_bert, y_train_bert), val_data=(X_test_bert, y_test_bert), batch_size=32)\n",
        "\n",
        "# find a good learning rate\n",
        "learner.lr_find()\n",
        "learner.lr_plot()\n",
        "\n",
        "# train using triangular learning rate policy\n",
        "learner.autofit(0.0007, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? True\n",
            "maxlen is 150\n",
            "done.\n",
            "simulating training for different learning rates... this may take a few moments...\n",
            "Train on 765 samples\n",
            "Epoch 1/1024\n",
            "765/765 [==============================] - 22s 28ms/sample - loss: 0.9553 - acc: 0.3871\n",
            "Epoch 2/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.9334 - acc: 0.3926\n",
            "Epoch 3/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.9006 - acc: 0.4105\n",
            "Epoch 4/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.8649 - acc: 0.4355\n",
            "Epoch 5/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.8226 - acc: 0.4667\n",
            "Epoch 6/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.7755 - acc: 0.4943\n",
            "Epoch 7/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.7238 - acc: 0.5285\n",
            "Epoch 8/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.6704 - acc: 0.5741\n",
            "Epoch 9/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.6212 - acc: 0.6028\n",
            "Epoch 10/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.5738 - acc: 0.6553\n",
            "Epoch 11/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.5327 - acc: 0.7608\n",
            "Epoch 12/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.4968 - acc: 0.8218\n",
            "Epoch 13/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.4646 - acc: 0.8320\n",
            "Epoch 14/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.4378 - acc: 0.8362\n",
            "Epoch 15/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.4162 - acc: 0.8407\n",
            "Epoch 16/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.3966 - acc: 0.8434\n",
            "Epoch 17/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.3775 - acc: 0.8458\n",
            "Epoch 18/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.3512 - acc: 0.8542\n",
            "Epoch 19/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.3175 - acc: 0.8649\n",
            "Epoch 20/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.2741 - acc: 0.8908\n",
            "Epoch 21/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.2294 - acc: 0.9168\n",
            "Epoch 22/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1941 - acc: 0.9237\n",
            "Epoch 23/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1612 - acc: 0.9412\n",
            "Epoch 24/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1337 - acc: 0.9547\n",
            "Epoch 25/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1166 - acc: 0.9603\n",
            "Epoch 26/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1021 - acc: 0.9647\n",
            "Epoch 27/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.0789 - acc: 0.9765\n",
            "Epoch 28/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.0601 - acc: 0.9826\n",
            "Epoch 29/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.0569 - acc: 0.9808\n",
            "Epoch 30/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.0644 - acc: 0.9789\n",
            "Epoch 31/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1394 - acc: 0.9444\n",
            "Epoch 32/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1441 - acc: 0.9458\n",
            "Epoch 33/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1921 - acc: 0.9305\n",
            "Epoch 34/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1733 - acc: 0.9305\n",
            "Epoch 35/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.1809 - acc: 0.9298\n",
            "Epoch 36/1024\n",
            "765/765 [==============================] - 14s 18ms/sample - loss: 0.2810 - acc: 0.8961\n",
            "Epoch 37/1024\n",
            "704/765 [==========================>...] - ETA: 1s - loss: 0.4163 - acc: 0.8409\n",
            "\n",
            "done.\n",
            "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n",
            "\n",
            "\n",
            "begin training using triangular learning rate policy with max lr of 0.0007...\n",
            "Train on 765 samples, validate on 85 samples\n",
            "Epoch 1/10\n",
            "765/765 [==============================] - 34s 44ms/sample - loss: 0.5399 - acc: 0.7590 - val_loss: 0.4078 - val_acc: 0.8529\n",
            "Epoch 2/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4580 - acc: 0.8296 - val_loss: 0.4173 - val_acc: 0.8529\n",
            "Epoch 3/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4528 - acc: 0.8296 - val_loss: 0.4091 - val_acc: 0.8529\n",
            "Epoch 4/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4498 - acc: 0.8296 - val_loss: 0.4093 - val_acc: 0.8529\n",
            "Epoch 5/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4528 - acc: 0.8296 - val_loss: 0.4070 - val_acc: 0.8529\n",
            "Epoch 6/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4514 - acc: 0.8296 - val_loss: 0.4042 - val_acc: 0.8529\n",
            "Epoch 7/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4582 - acc: 0.8296 - val_loss: 0.4148 - val_acc: 0.8529\n",
            "Epoch 8/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4505 - acc: 0.8296 - val_loss: 0.4073 - val_acc: 0.8529\n",
            "Epoch 9/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4531 - acc: 0.8296 - val_loss: 0.4184 - val_acc: 0.8529\n",
            "Epoch 10/10\n",
            "765/765 [==============================] - 15s 19ms/sample - loss: 0.4522 - acc: 0.8296 - val_loss: 0.4069 - val_acc: 0.8529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbbb8004c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAENCAYAAAACHGKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3gVZf7+8fcnnZKEFiAQmjSJFAmh\niohrw4pdsKBYULHv6q67ul9dy+qq609RitixIQgqIooNBQWE0DuGJk16ryF5fn+cw25kQwiQyZxy\nv64rF+fMmXPmzhhzZ9oz5pxDRESiV4zfAURExF8qAhGRKKciEBGJcioCEZEopyIQEYlyKgIRkSjn\nWRGY2Rtmtt7M5h7mdTOzfmaWa2azzSzLqywiInJ4Xm4RvAV0K+b1c4HGwa8+wEAPs4iIyGF4VgTO\nufHA5mJm6Q4McQGTgUpmlu5VHhERKVqcj8uuDaws9HxVcNra4t5UrVo1V79+fQ9jiYhEnmnTpm10\nzqUV9ZqfRVBiZtaHwO4j6tatS05Ojs+JRETCi5mtONxrfp41tBqoU+h5RnDa/3DODXbOZTvnstPS\niiw0ERE5Rn4WwSigV/DsoQ7ANudcsbuFRESk9Hm2a8jMPgC6AtXMbBXwCBAP4JwbBIwBzgNygd1A\nb6+yiIjI4XlWBM65nkd43QF3eLV8EREpGV1ZLCIS5VQEIiJRLmqKoKDAMf3XLazdtoeCAt2VTUTk\noLC4jqA0vPDNYvp9lwvAA+c05bKsDByO9NRyPicTEfFX1GwRXJFdh7MzawDw7NhFdHjqWzo+9R2v\njl/qczIREX9ZuN28Pjs72x3PlcUTl2xk/OKN7D9QwNTlm5mzehtnZdagfYMq1K5UjrMya7A7L5+U\npPhSTC0i4i8zm+acyy7qtajZNXRQp4bV6NSwGgAH8gt4cswCPpu1hq/nr/vdfBe0TOfP55xI3arl\n/YgpIlJmom6LoCgFBY71O/YxZs5aRkxfRWyMkbt+J3vy8uncqBoPnd+ME2umlOoyRUTKUnFbBCqC\nw1i5eTfvTl7Bu5NXsGt/Pmdn1uCx7s2pmZrk+bJFREqbiuA4/LZtL8NyVtJ/XC6xMcYVbTK48w+N\nSUtOLLMMIiLHq7giiJqzho5VzdQk7j6jMV/d14Uzm9Xg7UkrOPP5Hxies5K8/AK/44mIHDdtERyl\n+Wu28/dP5zJtxRYS42Lo0+UE7vpDYxLi1KkiErq0RVCKMmulMOzWjgy8JotTG1fjpe9yuejlH5nw\nywa/o4mIHBMVwTGIjTHObZHOa9e35dVe2WzatZ/r35jC46Pns277Xr/jiYgcFRXBcTorswY/PNCV\nzo3TeP3HZZz27DgG/bBExw9EJGyoCEpB+YQ4htzYjq/v68JpTdJ4+ouFXPTyT6zcvNvvaCIiR6Qi\nKEWNayTzynXZDLq2Das27+aSARP5fLbuvikioU1F4IFuzWsy9NYO1KqUxB3vT+eLOSoDEQldKgKP\nnFQrlY9u60SrjFT+PGI2M1du9TuSiEiRVAQeSoiL4bkrWpGcGMfVr07m7YnLOaCDyCISYlQEHmtc\nI5lP7jiFVhmVeGTUPC4e8BPjF+uaAxEJHSqCMlA9JYn3b2nPiz1OZvWWPVz/5hReHb+UcLuqW0Qi\nk4qgjJgZ3U+uzcQHz6DbSTV5cswC/jJiNjv3HfA7mohEORVBGSuXEEv/q7O44/SGDMtZxY1vTWVv\nXr7fsUQkiqkIfBATYzxwzon069maqcs3c+NbU9mlLQMR8YmKwEcXtarFv69oxc/LNtP7ranaTSQi\nvlAR+OzSrAxeuOpkpq3YQo/Bk1i/Q4PWiUjZUhGEgAtb1eK1XtksWb+LKwdNYr1GMBWRMqQiCBGn\nn1idt29sx5pte7lkwERy1+/0O5KIRAkVQQhp16AKI2/vxL4D+Vw2cCKzNCyFiJQBFUGIaV47lY/7\nnkJKuThuHpLD2m17/I4kIhFORRCC6lQpz+vXt2X3vgP0GTKN3ft1NpGIeEdFEKKa1EimX8/WzFuz\njV6vT9GWgYh4RkUQws5oVoPnrmhFzootnP7c93wzf53fkUQkAqkIQtylWRmMvqsz9apU4I/DZjJv\nzTa/I4lIhFERhIHmtVPpf01rzIxLB0zky7m645mIlB5Pi8DMupnZIjPLNbMHi3i9rpmNM7MZZjbb\nzM7zMk84a1Q9mW/+eBonpqdw74czmbRkk9+RRCRCeFYEZhYL9AfOBTKBnmaWechsDwPDnHOtgR7A\nAK/yRIK05EQGX9eGjMrl6fveNFZu3u13JBGJAF5uEbQDcp1zS51z+4GhQPdD5nFASvBxKrDGwzwR\noUZKEq/1yia/wHHjW1PZvjfP70giEua8LILawMpCz1cFpxX2KHCtma0CxgB3FfVBZtbHzHLMLGfD\nBt3msX61Cgy6tg25G3Zy2zvTdB9kETkufh8s7gm85ZzLAM4D3jGz/8nknBvsnMt2zmWnpaWVechQ\n1KlRNZ64uDkTl2yi37e/+B1HRMKYl0WwGqhT6HlGcFphNwHDAJxzk4AkoJqHmSLKNe3rcVlWBi+P\ny2XyUh08FpFj42URTAUam1kDM0sgcDB41CHz/AqcAWBmzQgUgfb9HIV/dD+JelUrcN+HM9m4c5/f\ncUQkDHlWBM65A8CdwFhgAYGzg+aZ2WNmdlFwtj8Bt5jZLOAD4AbnnPMqUySqmBhHvx6t2bxrP1cM\nmsSSDRq+WkSOjoXb793s7GyXk5Pjd4yQk7N8M7e+M41yCbF8eW8XKibG+R1JREKImU1zzmUX9Zrf\nB4ullGTXr8Ir17Vh9dY9PDB8FgUF4VXwIuIfFUEEya5fhYfOa8YXc3/jsdHzVQYiUiLafxBhburc\ngFVb9vDWxOVUKh/PvWc28TuSiIQ4bRFEGDPjkQszuaBlOgO/X8KMX7f4HUlEQpyKIAKZGQ+fn0m1\nionc+s40nVYqIsVSEUSomqlJvNorm6178rjvw5k6XiAih6UiiGCZtVJ49MKTmPDLRgZ8n+t3HBEJ\nUSqCCNezXR0ualWL579ezM8ahkJEiqAiiHBmxj8vbUG9qhW4e+gMHS8Qkf+hIogCFRPj6H91Flt2\n63iBiPwvFUGUyKyVwiMXZjLhl408M3aR33FEJISoCKLI1e3qcnX7ugz6YQnfLljndxwRCREqgihi\nZjx64Uk0rZHMfR/OZNnGXX5HEpEQoCKIMglxMbx2fTYxMUbvN6ewdtsevyOJiM9UBFGoTpXyDLq2\nDet37OPqV39m6+79fkcSER+pCKJUhxOq8sYNbVm9ZQ/3DJ1Jvs4kEolaKoIo1uGEqjxyUSY/LN7A\ni98s9juOiPhERRDlrm5XlyvaZNDvu1y+ma8ziUSikYogypkZj1/cnOa1U7hv2EyW60wikaijIhCS\n4mMZeE0bYmOMW9+Zxu79B/yOJCJlSEUgQOBMon49WrN4/Q4eHDEH53TwWCRaqAjkP7o0SeP+s5sy\natYa3vxpud9xRKSMqAjkd24/rSFnZdbgn2MWMGXZZr/jiEgZUBHI78TEGP++shV1q5Sn73vTWbd9\nr9+RRMRjKgL5HylJ8Qy6rg279x+g1+sahkIk0qkIpEhNaiTzWq9sVm/dw/VvTGHP/ny/I4mIR1QE\nclidGlWj/zVZLF63kz7v5OhMIpEIpSKQYp3WJI1Hgze00ZlEIpFJRSBHdH2n+pzZrAZPjlnAJzNW\na8tAJMKoCOSIzIwXe5xMVt1K3PvhTHq9MYUde/P8jiUipURFICVSITGO927uwCMXZjJxySae+mKh\n35FEpJSoCKTEEuJi6H1KA65tX5ehU37lx182+h1JREqBikCO2p+7nUjDtIrcP3wWKzfv9juOiBwn\nFYEctQqJcfy/q05m9/4D3P7eNAp0dzORsKYikGPSvHYq/+h+EnNXb+fPI2ZzIL/A70gicow8LQIz\n62Zmi8ws18wePMw8V5rZfDObZ2bve5lHSlf3VrW5uXMDPpq2igdHzvE7jogcozivPtjMYoH+wFnA\nKmCqmY1yzs0vNE9j4K/AKc65LWZW3as8UvpiYoyHL8gkPi6Ggd8v4fI2GXQ4oarfsUTkKHm5RdAO\nyHXOLXXO7QeGAt0PmecWoL9zbguAc269h3nEI/ec0ZhaqUk8Pnq+dhGJhCEvi6A2sLLQ81XBaYU1\nAZqY2U9mNtnMunmYRzySFB/L385vxrw123n+68V+xxGRo+T3weI4oDHQFegJvGpmlQ6dycz6mFmO\nmeVs2LChjCNKSVzQshYXtExn4A9L+HbBOr/jiMhR8LIIVgN1Cj3PCE4rbBUwyjmX55xbBiwmUAy/\n45wb7JzLds5lp6WleRZYjs9Tl7agYVpFbh6Sw2sTlvodR0RKyMsimAo0NrMGZpYA9ABGHTLPJwS2\nBjCzagR2Fek3SJhKTorn476dOKVhNZ74fAFfzFnrdyQRKQHPisA5dwC4ExgLLACGOefmmdljZnZR\ncLaxwCYzmw+MAx5wzm3yKpN4Lzkpnjd7t6VlRip/+3iObnUpEgYs3IYUzs7Odjk5OX7HkCPIXb+T\nC1/6kaT4GAZe20anlYr4zMymOeeyi3rN74PFEqEaVa/IsFs7UqVCArcMyWHWyq1+RxKRw1ARiGda\nZKTy5g3tSC0Xzw1vTmH11j1+RxKRIqgIxFN1q5bnnZvas+9AAee+MJ6JSzR0tUioURGI5xpUq8B7\nN7cntXw8fYZMY9qKLX5HEpFCVARSJlrXrcywWzuSWi6eywZOZOiUX/2OJCJBKgIpM+mp5RjZtxMp\nSXE8OHIOX87VdQYioaBERWBm95hZigW8bmbTzexsr8NJ5KmRksSnd3amVmoS9w+fzdINO/2OJBL1\nSrpFcKNzbjtwNlAZuA542rNUEtEaVKvA8Ns7ER9r3PDmVFZs2uV3JJGoVtIisOC/5wHvOOfmFZom\nctRqVyrHGze0ZfvePO58fwa79h3wO5JI1CppEUwzs68IFMFYM0sGNPC8HJfWdSvz9KUtmLN6G1cN\nnkTu+h1+RxKJSiUtgpuAB4G2zrndQDzQ27NUEjW6NU9n0LVtyF2/k+4v/8S4Rbo3kUhZK2kRdAQW\nOee2mtm1wMPANu9iSTTp1rwm4+7vSv1qFbjl7Rw+n62ziUTKUkmLYCCw28xaAX8ClgBDPEslUSc9\ntRxD+3TgpNqp3PH+dP7x2Ty/I4lEjZIWwQEXGKa0O/Cyc64/kOxdLIlGyUnxDL+1Iz3b1eHNn5bz\n549msWXXfr9jiUS8uBLOt8PM/krgtNFTzSyGwHECkVKVEBfD492bUzExjtd/XMbidTsZ2qcDSfGx\nfkcTiVgl3SK4CthH4HqC3wjcdvJZz1JJVIuLjeGh8zMZcE0WM1du5bRnx/Hu5BV+xxKJWCUqguAv\n//eAVDO7ANjrnNMxAvFUt+bpDLgmi9qVyvHwJ3N5YPgsXW8g4oGSDjFxJTAFuAK4EvjZzC73MpgI\nwHkt0hl+Wyeu61CPj6av4u+fzvU7kkjEKekxgocIXEOwHsDM0oBvgI+8CiZyUGyM8fjFzUkpF0f/\ncUu4MruObn0pUopKeowg5mAJBG06iveKlIq+XRtRu1I5rnv9Z14dv9TvOCIRo6S/zL80s7FmdoOZ\n3QB8DozxLpbI/6qQGMeHt3agVUYlnhyzgKe/WMi+A/l+xxIJexa4PKAEM5pdBpwSfDrBOfexZ6mK\nkZ2d7XJycvxYtISI/ALHXR9MZ8yc36iYGMejF53EZVm1MdM4iCKHY2bTnHPZRb5W0iIIFSoCAXDO\n8d3C9dz1wQx278/nzGbV6Xt6I7LqVvY7mkhIKq4Iit01ZGY7zGx7EV87zGy7N3FFjszMOKNZDb64\n51Tu/kMjJi/dzOUDJ+p+yCLHQFsEEhG27cnjvBcnkBgXw5h7TtWVyCKHOOYtApFwkVounmcub8nS\njbs454XxfDZrDdv35vkdSyQsqAgkYpzSqBrPXdGK/QcKuOuDGZz9/Hh+Waeb3YgciXYNScTZtjuP\nsfN/419fLGRTcPTSd25qx6mN03xOJuIf7RqSqJJaPp4rs+vwcd9TyKhcDoDrXp9CzvLNPicTCU0q\nAolYdauW58e//IHv/nQaqeXiuXzQJP45ZgE7NXCdyO+oCCTinZBWkfdubs/5LdMZPH4pN701lY07\n9/kdSyRkqAgkKjSvnUr/q7N4+tIWTFm+mQ7//JZ3Jq9gb56GqBBREUhU6dGuLq/1yqZu1fL8/ZO5\nnN9vAis37/Y7loivVAQSdc5oVoOv7u1C364NWb5pN6c+M45HPp3LpCWb/I4m4gsVgUSluNgY/tzt\nRD7u2wmAtyetoOerkxnwfS75BeF1SrXI8VIRSFRrmVGJxU+cyz8vaUGz9BSe+XIRpz07jvlrNJSW\nRA9Pi8DMupnZIjPLNbMHi5nvMjNzZlbkxQ4iXkqIi+Hq9nUZc3dn7j2zMRt27OPi/j8xZNJyxi1c\nT15+gd8RRTzl2ZXFZhYLLAbOAlYBU4Gezrn5h8yXTOBGNwnAnc65Yi8b1pXF4rUVm3bxwEezmbIs\ncAHa+S3S6dezNbExut+BhC+/rixuB+Q655Y65/YDQ4HuRcz3OPAvYK+HWURKrF7VCrzdux2PdT+J\nUxpV5fM5a+n73jT2H9CWgUQmL4ugNrCy0PNVwWn/YWZZQB3n3OfFfZCZ9TGzHDPL2bBhQ+knFTlE\nuYRYenWsz7s3teeeMxozdt46sh7/midGz2fVFp1uKpHFt4PFZhYDPA/86UjzOucGO+eynXPZaWka\nOEzKjplx75mNuffMxtRMTeLtScu58KUfWbZxl9/RREqNl0WwGqhT6HlGcNpByUBz4HszWw50AEbp\ngLGEmkAZNOGbP57GR7d1Yk9ePhe+9KOuO5CI4WURTAUam1kDM0sAegCjDr7onNvmnKvmnKvvnKsP\nTAYuOtLBYhE/tapTiZG3n0KVCgncMiSHibkb/Y4kctw8KwLn3AHgTmAssAAY5pybZ2aPmdlFXi1X\nxGuZtVL48NYOVE9J5OrXfuaWITms36FzHSR86cY0Isdo2548Hh89n4+mraJKhQT6X51Fx4ZV/Y4l\nUiTdmEbEA6nl4nnuilaMuL0TqeXi6fnqZB75dK4uQJOwoyIQOU5t6lVm1J2ncEOn+oExiwZP5oMp\nv2rMIgkbcX4HEIkEyUnxPHrRSWTWSuHBEbPJWbGFqcs28/RlLUmI099bEtr0EypSiq7MrsOM/zub\nO09vxMgZq7l80ETd70BCnopApJSllovn/nOaMuCaLBas3U63F8bzt4/n6F7JErK0a0jEI+e1SKdR\n9Yr0+/YX3v/5Vzbu2MeAa7KIi9XfXxJa9BMp4qEmNZJ5+eosLm+TwVfz13HPhzMJt1O2JfJpi0Ck\nDDx5SXNqpSbR77tcTqqVQt+ujfyOJPIf2iIQKQOJcbHcd1YTzm+ZznNjFzF5qcYpktChIhApI2bG\n38/PpFL5BK5+dTKfzFh95DeJlAEVgUgZqpmaxLj7u9K+QVXuGzaTN35cpmMG4jsVgUgZSy0Xzxs3\ntKVL4zQeGz2f1yYs8zuSRDkVgYgPyiXE8lbvtpzWJI0XvlnMwt+2+x1JopiKQMQnZsa/LmtJhcQ4\nbnorh4079/kdSaKUikDERzVTk3jt+mw27drH5QMnMnf1Nr8jSRRSEYj4rGVGJZ6/8mSWb9pN9/4/\n8fxXi9ibl+93LIkiKgKREHBei3R+eKArF7RMp993ufzt4zl+R5IooiuLRUJEvaoVeLFHazIql6P/\nuCVUq5jIX889ETPzO5pEOBWBSIj541lN2bRzP4PHLyUhNob7z2nqdySJcNo1JBJiYmOMx7o3J6Ny\nOV4el8vo2Wv8jiQRTkUgEoIS4mL47k9dya5XmQeGz2bKss1+R5IIpiIQCVEJcTEMuDaLtOREbn93\nGqNmactAvKEiEAlh1ZOTGHBNFpXKx3P3BzP4dKYGqotGB/ILuGVIDj/+stGTz1cRiIS45rVT+fLe\nLrStX5kHR8zhh8Ub/I4kZeynJZv4ev46du335nanKgKRMBAfG8PLV2dRPSWRG9+ayuez1/odScrQ\nqJlrSE6Ko2vTNE8+X0UgEiZqpCQx+q7OtK5TibuHajdRtNi2O4/P56zh/BbpJMbFerIMFYFIGElO\niuftG9uRXa8y9304k5HTV/kdSTz2Yc6v7M0roFfH+p4tQ0UgEmYqJMbxZu+2dDihKn8aPothU1f6\nHUk8NHTqStrVr0JmrRTPlqEiEAlD5RPieOOGtnRuVI0/j5jNB1N+9TuSeGDZxl0s3bCLbs1reroc\nFYFImEqKj+XVXtl0bZrGX0fO0ZZBBBo69VfiY41zW6gIROQwkuJjGXRtG05tXI0HR85mvE4tjSgT\nczeRVbcy6anlPF2OikAkzCXFxzLgmiwaplWk91tTeW3CUgoKnN+x5Dht25PHvDXb6HBCVc+XpSIQ\niQDJSfGM7NuJ05um8cTnC7j13Wns2ufNxUfivYlLNnLhSz9S4KBLk2qeL09FIBIhkpPiebVXNn+/\nIJPvFq7nutd/1n2Qw9C8Ndu44Y2p5Bc4nrmsJW3qVfF8mSoCkQhiZtzUuQHPXdGSuau30/vNqaze\nusfvWHIU/jFqPpXKx/PZXZ25sm2dMlmmp0VgZt3MbJGZ5ZrZg0W8/kczm29ms83sWzOr52UekWhx\nSesM+vU8mWUbd3Fx/59YvG6H35GkBBav28GU5Zu5+dQGVKmQUGbL9awIzCwW6A+cC2QCPc0s85DZ\nZgDZzrmWwEfAM17lEYk23ZqnM7JvJwy46pVJzF611e9IUgznHK/8ELgr3eVtymZL4CAvtwjaAbnO\nuaXOuf3AUKB74Rmcc+Occ7uDTycDGR7mEYk6TWokM/y2jlRIjKPH4MkauTSEPfXFQkZMX0WvjvXK\ndGsAvC2C2kDhK1xWBacdzk3AFx7mEYlK9apWYGTfTtSvWoFb38nhizkauTTUFBQ4hk75lfNa1OSh\n85uV+fJD4mCxmV0LZAPPHub1PmaWY2Y5GzboLxqRo1U9OYm3b2xHrdRy3P7edG4ZksNOnV4aMr5d\nuJ7tew9wdmZNzKzMl+9lEawGCu/oyghO+x0zOxN4CLjIOVfkuW7OucHOuWznXHZamjfjcYtEurTk\nRL68twu9T6nPNwvW0fvNKSqDEDFxyUaS4mM4v2W6L8v3sgimAo3NrIGZJQA9gFGFZzCz1sArBEpg\nvYdZRITAfZAfufAkXu6ZxfRft9L95R/5bNYaDuQX+B0tqq3asoe6VcoTH+vPThrPluqcOwDcCYwF\nFgDDnHPzzOwxM7soONuzQEVguJnNNLNRh/k4ESlF57dM5+WerdmbV8BdH8zgD//+ge8WrvM7VtRa\ntWUPtSt5O55QceK8/HDn3BhgzCHT/q/Q4zO9XL6IHN65LdI5K7MGI2esZtD3S7j7g5m82bstbet7\nfyWr/Nf2vXksWLudrk0b+pYhJA4Wi4g/4mJjuDK7Dm/1bkfVign0GDyZ139chnMatK4sbNm1n0v6\n/wRAl8b+Hf/0dItARMJD3arlGX1XZ/44bBaPj57P7FVbeerSFpRP0K+I0jA8ZyWjZq1h+548ChzE\nxhgzV/73Ar/bTmtIx4bejzJ6OPqvLCJAYNC6V65tw8AflvDcV4tY9NsOXrmuDfWqVvA7Wtj6aNoq\nHvp4DvsOBA7GJ8TGUDEpjkrl4smqW4m8fMcD5zSlSxN/z4a0cNsEzM7Odjk5OX7HEIloPyzewN0f\nzGDfgXwuaZ3BQ+c3o2Ki/m4szg+LN/CvLxZSIyWRq9vXY932vTz8yVwqlY/nvjOb8IcTq1MxMY7K\nZXzV8EFmNs05l13kayoCESnKys27eem7XxiWs4qUpDhuOfUEbj2tIQlxOrR4qLXb9tDlmXHk5Tsq\nJsb95/qMulXKM/ruzqQkxfucUEUgIsdh6vLN9B+Xy/eLNpCZnsIjF2bSvgzumhWKlm3cxYK124kx\nqFYxkTXb9rJ84y7e+GkZ2/bk8XbvdmTXr8yQSSuoW6U8XZumhcxxFhWBiBy3L+eu5eFP5rJx5366\nn1yLO05vRJMayX7HKhM79ubxyKh5jJz+P4Mj/Mend5xCqzqVyjDV0SmuCEKjqkQk5HVrns5pTaoz\n6IclDPg+l1Gz1nBVdh0eOKcpVSsm+h3PE8453pm8gqe/WMju/fmc2aw6WfUqUyu1HL9u3k29quVZ\nuXk31ZOTQroEjkRbBCJy1Dbu3MfzXy9m2NSVxMfGcPOpDbj7jMa+DZFQ2goKHMOnreSpLxaydXce\nAC9cdTIXty5uAOXQpl1DIuKJRb/t4PmvFzF23jraN6jCy1dnkZYc/lsH//fpXIZMWsGJNZPpcEJV\nrmlfl8ZhvhtMRSAinvpkxmr+MmI2CXEx/O28ZvRoW8eX4ZRLw/4DBbT6x1f84cTqvNjjZOIiZCun\nuCKIjO9QRHx1cevafH53Z1rUTuWvI+dw5/sz2LJrv9+xjopzjqfGLKDjU9+yJy+fy9tkREwJHEl0\nfJci4rlG1ZN596b2PHBOU76c9xttn/yGB0fMJnf9Tr+jlcjAH5bwyvilpCUn8uiFmXRtGj33PtFZ\nQyJSamJijDtOb0SnhlUZlrOSkdNXM3TqSs7OrMF9ZzWhWXqK3xF/J7/AsWDtdhav28EzXy6iXf0q\nDO3TgZiY8NytdaxUBCJS6lrXrUzrupW5/+ymvD1pBW9PXM6FL/3IHac34o7TG/l6dfKCtdvZte8A\n+/ML6Pve9P+cFQRw86kNoq4EQAeLRaQMbNm1n8dGz+fjGatJT03i2g71uKptHaqV4fUH2/bk8eTn\n8xkxfTX5BYHfe7VSkzj7pJp0bFiVxtUrckJaxTLLU9Z01pCIhIRv5q9j4A9LmLZiCxUSYrm9a0Nu\n6nwC5RJiPV3uzJVbuTg47v+ZzWrQ4YQqbN97gF4d65VpGflJRSAiIWXhb9t5/qvFfDV/HTVTkujT\n5QQuOrmWJ7+U9+bl0+z/vsQ5uLlzAx6+ILPUlxEOVAQiEpKmLNvMU18sYMavW0mIi+HWLidwe9eG\npTZQ27CpK3nx219YvXUPfbqcwN/Oa1YqnxuOVAQiErIKChxTlm/mgym/8unMNSTFx9C+QVWuyM7g\n/Bbpx3xh2msTlvLE5wtoUJumkAwAAAlBSURBVK0C13WoR6+O9aLmuoCiqAhEJCzkLN/MkEkr+HzO\nWvILHNUqJtC1aXXOa1GTzo3SSny20aLfdnDui+Pp0iSNV65rQ2Kct8cgwoGKQETCSn6BY/TsNYxb\nuJ5vF6xnx74DVKuYwOlNq9O2QRXOOLE6yUnxRRbDqi27uWLQJLbvyePjO06JmqGyj0RFICJha29e\nPhN+2cgnM1czYfEGtu8N3P0rLsbIqluZ2Bjjl/U7SYyL4UBBAeu278MMhtzYjlMbR8/VwUei+xGI\nSNhKio/lrMwanJVZg4ICx8LfdvD5nDVs2rmfBWu3Y2Zk1kphX14+ifGxXNEmlYtOrqUtgaOgIhCR\nsBETE/iln1krtIaqCHfRewhdREQAFYGISNRTEYiIRDkVgYhIlFMRiIhEORWBiEiUUxGIiEQ5FYGI\nSJQLuyEmzGwDsKLQpFRgWzHPqwEbPYx06PK8eF9x8x7tayWZFmnr8EjzaR0e/3xah8c/n9frsJ5z\nrugxN5xzYf0FDD7C85yyXL4X7ytu3qN9rSTTIm0dHmk+rUOtw2hZh4f7ioRdQ58d4XlZL9+L9xU3\n79G+VpJpkbYOjzSf1uHxz6d1ePzz+bYOw27X0NEysxx3mBH3pGS0Do+f1uHx0zr0TiRsERzJYL8D\nRACtw+OndXj8tA49EvFbBCIiUrxo2CIQEZFiqAhERKKcikBEJMpFdRGY2almNsjMXjOziX7nCTdm\nFmNmT5rZS2Z2vd95wpGZdTWzCcGfw65+5wlXZlbBzHLM7AK/s4SjsC0CM3vDzNab2dxDpnczs0Vm\nlmtmDxb3Gc65Cc6524DRwNte5g01pbH+gO5ABpAHrPIqa6gqpXXogJ1AElqHhacfzToE+AswzJuU\nkS9szxoysy4E/gca4pxrHpwWCywGziLwP9VUoCcQCzx1yEfc6JxbH3zfMOAm59yOMorvu9JYf8Gv\nLc65V8zsI+fc5WWVPxSU0jrc6JwrMLMawPPOuWvKKn8oKKV12AqoSqBMNzrnRpdN+sgRtjevd86N\nN7P6h0xuB+Q655YCmNlQoLtz7imgyE1GM6sLbIumEoDSWX9mtgrYH3ya713a0FRaP4NBW4BEL3KG\nslL6OewKVAAygT1mNsY5V+Bl7kgTtkVwGLWBlYWerwLaH+E9NwFvepYovBzt+hsJvGRmpwLjvQwW\nRo5qHZrZpcA5QCXgZW+jhY2jWofOuYcAzOwGgltYnqaLQJFWBEfNOfeI3xnClXNuN4EilWPknBtJ\noFDlODnn3vI7Q7gK24PFh7EaqFPoeUZwmpSM1t/x0zo8flqHZSzSimAq0NjMGphZAtADGOVzpnCi\n9Xf8tA6Pn9ZhGQvbIjCzD4BJQFMzW2VmNznnDgB3AmOBBcAw59w8P3OGKq2/46d1ePy0DkND2J4+\nKiIipSNstwhERKR0qAhERKKcikBEJMqpCEREopyKQEQkyqkIRESinIpAPGdmO8tgGReVcLji0lxm\nVzPrdAzva21mrwcf32BmITHGkJnVP3Q46CLmSTOzL8sqk5QNFYGEjeDwxEVyzo1yzj3twTKLG4+r\nK3DURQD8Deh3TIF85pzbAKw1s1P8ziKlR0UgZcrMHjCzqWY228z+UWj6J2Y2zczmmVmfQtN3mtm/\nzWwW0NHMlpvZP8xsupnNMbMTg/P95y9rM3vLzPqZ2UQzW2pmlwenx5jZADNbaGZfm9mYg68dkvF7\nM3vBzHKAe8zsQjP72cxmmNk3ZlYjOHTybcB9ZjbTAne7SzOzEcHvb2pRvyzNLBlo6ZybVcRr9c3s\nu+C6+TY4RDpm1tDMJge/3yeK2sKywB26PjezWWY218yuCk5vG1wPs8xsipklB5czIbgOpxe1VWNm\nsWb2bKH/VrcWevkTIKrumxDxnHP60penX8DO4L9nA4MBI/BHyGigS/C1KsF/ywFzgarB5w64stBn\nLQfuCj7uC7wWfHwD8HLw8VvA8OAyMgmMbQ9wOTAmOL0mgXsAXF5E3u+BAYWeV+a/V+HfDPw7+PhR\n4P5C870PdA4+rgssKOKzTwdGFHpeOPdnwPXBxzcCnwQfjwZ6Bh/fdnB9HvK5lwGvFnqeCiQAS4G2\nwWkpBEYcLg8kBac1BnKCj+sDc4OP+wAPBx8nAjlAg+Dz2sAcv3+u9FV6X1E/DLWUqbODXzOCzysS\n+EU0HrjbzC4JTq8TnL6JwA1vRhzyOQeHbZ4GXHqYZX3iAuPSz7fA3b8AOgPDg9N/M7NxxWT9sNDj\nDOBDM0sn8Mt12WHecyaQaWYHn6eYWUXnXOG/4NOBDYd5f8dC3887wDOFpl8cfPw+8FwR750D/NvM\n/gWMds5NMLMWwFrn3FQA59x2CGw9AC+b2ckE1m+TIj7vbKBloS2mVAL/TZYB64Fah/keJAypCKQs\nGfCUc+6V300M3GHqTKCjc263mX1P4LaDAHudc4fe/Wxf8N98Dv8zvK/QYzvMPMXZVejxSwRuIzkq\nmPXRw7wnBujgnNtbzOfu4b/fW6lxzi02syzgPOAJM/sW+Pgws98HrCNwi8cYoKi8RmDLa2wRryUR\n+D4kQugYgZSlscCNZlYRwMxqm1l1An9tbgmWwIlAB4+W/xNwWfBYQQ0CB3tLIpX/jod/faHpO4Dk\nQs+/Au46+CT4F/ehFgCNDrOciQSGXIbAPvgJwceTCez6odDrv2NmtYDdzrl3gWeBLGARkG5mbYPz\nJAcPfqcS2FIoAK4jcC/gQ40Fbjez+OB7mwS3JCCwBVHs2UUSXlQEUmacc18R2LUxyczmAB8R+EX6\nJRBnZguApwn84vPCCAK3PZwPvAtMB7aV4H2PAsPNbBqwsdD0z4BLDh4sBu4GsoMHV+cT2J//O865\nhUBq8KDxoe4CepvZbAK/oO8JTr8X+GNweqPDZG4BTDGzmcAjwBPOuf3AVQRuJzoL+JrAX/MDgOuD\n007k91s/B71GYD1ND55S+gr/3fo6Hfi8iPdImNIw1BJVDu6zN7OqwBTgFOfcb2Wc4T5gh3PutRLO\nXx7Y45xzZtaDwIHj7p6GLD7PeAI3k9/iVwYpXTpGINFmtJlVInDQ9/GyLoGggcAVRzF/GwIHdw3Y\nSuCMIl+YWRqB4yUqgQiiLQIRkSinYwQiIlFORSAiEuVUBCIiUU5FICIS5VQEIiJRTkUgIhLl/j8A\nhKhSvPg+YwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHHq1IsKCzrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "#bert_pred_prob = predictor.predict_proba(X_test)\n",
        "bert_pred = learner.model.predict(X_test_bert, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yfcj_k7FcROx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "03a3846b-adbe-4c45-f777-726e918d8c52"
      },
      "source": [
        "# Show the inputs and predicted outputs\n",
        "for i in range(5):\n",
        "  print(\"X=%s,\\nPredicted=%s\" % (tokenizer.sequences_to_texts(X_test_bert)[i],bert_pred[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X=when you take your case to washington d c you are taking it to the criminal who is responsible it is like running from the wolf to the fox they are all in cahoots together they all work political chicanery and make you look like a chump before the eyes of the world here you are walking around in america getting ready to be drafted and sent abroad like a tin soldier and when you get over there people ask you what are you fighting for and you have to stick your tongue in your cheek no take uncle sam to court take him before the world,\n",
            "Predicted=[0.268759   0.10832    0.1419129  0.16500017 0.1977604  0.16004488]\n",
            "X=we invite this congress and through it the scientists of the world and the general public to subscribe to the following resolution ï¿½in view of the fact that in any future world war nuclear weapons will certainly be employed and that such weapons threaten the continued existence of mankind we urge the governments of the world to realize and to acknowledge publicly that their purpose cannot be furthered by a world war and we urge them consequently to find peaceful means for the settlement of all matters of dispute between them ï¿½,\n",
            "Predicted=[0.2687602  0.10832131 0.14191306 0.16500017 0.19776097 0.1600456 ]\n",
            "X=soldiers donï¿½t give yourselves to brutes men who despise you enslave you who regiment your lives tell you what to do what to think and what to feel who drill you diet you treat you like cattle use you as cannon fodder donï¿½t give yourselves to these unnatural men machine men with machine minds and machine hearts you are not machines you are not cattle you are men you have the love of humanity in your hearts you donï¿½t hate only the unloved hate the unloved and the unnatural soldiers donï¿½t fight for slavery fight for liberty,\n",
            "Predicted=[0.26876426 0.10832259 0.14191416 0.1649985  0.197761   0.16004601]\n",
            "X=self awareness is a wonderful thing i know i will die soon so will you and everyone else maybe we will be lucky and a comet will smash us back to day 1 people say it is immoral to follow others they say be a leader well here is a fuckin news flash for you stupid shits everyone is a follower everyone who says they arenï¿½t followers and then dresses different or acts different they got that from something they saw on tv or in film or in life no originality how many yo mamma jokes are there and how many do you think are original and not copied keine,\n",
            "Predicted=[0.26875925 0.10832199 0.14191389 0.16500136 0.19776082 0.16004565]\n",
            "X=discuss anything that we differ about because it is time for us to submerge our differences and realize that it is best for us to first see that we have the same problem a common problem a problem that will make you catch hell whether you are a baptist or a methodist or a muslim or a nationalist whether you are educated or illiterate whether you live on the boulevard or in the alley you are going to catch hell just like i am we are all in the same boat and we all are going to catch the same hell from the same man he just happens to be a white man all of us have suffered here in this country political oppression at the hands of the white man economic exploitation at the hands of the white man and social degradation at the hands of the white man,\n",
            "Predicted=[0.2687618  0.10832277 0.14191356 0.16500002 0.19776064 0.16004628]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae0YLm59nN00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "92eac396-8267-47e6-fede-af0665cff196"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "ROC_score = roc_auc_score(y_test_bert, bert_pred)\n",
        "AP_score = average_precision_score(y_test_bert, bert_pred)\n",
        "print(\"\\n ROC-AUC score: %.2f \\n\" % (ROC_score))\n",
        "print(\"\\n AP score: %.2f \\n\" % (AP_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ROC-AUC score: 0.65 \n",
            "\n",
            "\n",
            " AP score: 0.26 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}